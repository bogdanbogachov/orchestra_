experiment: "cc_custom_head_test"

evaluation:
  head: "custom_head"   # "default_head" | "custom_head"

model:
  use_custom_head: true
  pooling_strategy: "mean"
  use_fft: true
  fft_adaptive: true  # true for learnable adaptive filtering, false for fixed 50% cutoff

  num_labels: 77
  pad_token: "<|reserved_special_token_15|>"
  torch_dtype: "float32"
  device_map: "auto"

paths:
  model: "downloaded_models/downloaded_3_2_1b"
  experiments: "experiments"
  data:
    training: "training_data.json"
    train: "train_data.json"
    test: "test_data.json"

lora:
  r: 4
  lora_alpha: 16
  target_modules:
    - "q_proj"
#    - "k_proj"
    - "v_proj"
#    - "o_proj"
  lora_dropout: 0.1
  bias: "none"

training:
  seed: null  # Set to null for non-deterministic training, or an integer for reproducibility
  max_length: 512
  num_train_epochs: 45  # Max epochs (early stopping will stop earlier if no improvement)
  per_device_train_batch_size: 48  # Will be combined with gradient_accumulation_steps to achieve effective_batch_size
  per_device_eval_batch_size: 48
  effective_batch_size: 48  # Effective batch size = per_device_train_batch_size * gradient_accumulation_steps
  gradient_accumulation_steps: null  # Auto-calculated from effective_batch_size if null
  learning_rate: 0.00002
  # Learning rate schedule
  lr_scheduler_type: "cosine"  # Options: "linear", "cosine", "cosine_with_restarts", "polynomial", "constant"
  warmup_steps: null  # If null, warmup_ratio will be used
  warmup_ratio: 0.1  # 10% of training steps for warmup
  # Early stopping
  early_stopping_patience: 3  # Number of evaluation steps without improvement before stopping
  early_stopping_threshold: 0.003  # Minimum change to qualify as an improvement
  # Evaluation and saving
  logging_steps: 10
  eval_steps: 25
  eval_strategy: "steps"
  save_strategy: "steps"  # Changed from "no" to save checkpoints for early stopping
  save_steps: null  # If null, will use eval_steps
  save_total_limit: 3  # Keep only the best 3 checkpoints to save disk space
  load_best_model_at_end: true  # Load best model based on validation metric
  metric_for_best_model: "eval_loss"  # Metric to use for best model selection
  greater_is_better: false  # False for loss (lower is better), true for accuracy
  fp16: true

data_processing:
  test_size: 0.2
  random_state: 42
  stratify: true

logging:
  log_dir: "logs"
